{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ffb1e91df2dc45de802e3670f1751232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24f7c8e0517a4d27afe4cf2e57729d26",
              "IPY_MODEL_f1645b16885a4ae586e1da6e1ba407a3",
              "IPY_MODEL_32322996f2c74a16b74723e13df60cd6"
            ],
            "layout": "IPY_MODEL_a2ff2f1582b24065bd0cbc23d434b564"
          }
        },
        "24f7c8e0517a4d27afe4cf2e57729d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14f3b0e2e8a643d4a3c807744a2aaa92",
            "placeholder": "​",
            "style": "IPY_MODEL_0f6c1b97c03640338ef3f19f994d81cf",
            "value": "Training:   0%"
          }
        },
        "f1645b16885a4ae586e1da6e1ba407a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b719521bee4458eae5b8c6f6c2ab59b",
            "max": 86,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e14251bca84340959b83a3e348e8acce",
            "value": 0
          }
        },
        "32322996f2c74a16b74723e13df60cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_228a2902f8864ff9b49e3e86f7b014bf",
            "placeholder": "​",
            "style": "IPY_MODEL_38875a44e80246daa2e9b6bfada324f2",
            "value": " 0/86 [00:00&lt;?, ?it/s]"
          }
        },
        "a2ff2f1582b24065bd0cbc23d434b564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14f3b0e2e8a643d4a3c807744a2aaa92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f6c1b97c03640338ef3f19f994d81cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b719521bee4458eae5b8c6f6c2ab59b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e14251bca84340959b83a3e348e8acce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "228a2902f8864ff9b49e3e86f7b014bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38875a44e80246daa2e9b6bfada324f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nfl_data_py\n",
        "!pip install pandas numpy torch tabulate matplotlib tqdm scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syrc_MiN4NVq",
        "outputId": "8b99779c-ada7-489a-f045-bcfb7e4e2bf0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nfl_data_py\n",
            "  Downloading nfl_data_py-0.3.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from nfl_data_py) (1.26.4)\n",
            "Collecting pandas<2.0,>=1.0 (from nfl_data_py)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting appdirs>1 (from nfl_data_py)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting fastparquet>0.5 (from nfl_data_py)\n",
            "  Downloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting cramjam>=2.3 (from fastparquet>0.5->nfl_data_py)\n",
            "  Downloading cramjam-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet>0.5->nfl_data_py) (2024.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet>0.5->nfl_data_py) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.0->nfl_data_py) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.0->nfl_data_py) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.0,>=1.0->nfl_data_py) (1.16.0)\n",
            "Downloading nfl_data_py-0.3.3-py3-none-any.whl (13 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cramjam-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, cramjam, pandas, fastparquet, nfl_data_py\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.3 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed appdirs-1.4.4 cramjam-2.9.0 fastparquet-2024.11.0 nfl_data_py-0.3.3 pandas-1.5.3\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dL5JzU_4Auh",
        "outputId": "b2af0efd-7ab3-4309-c210-a386ca08be4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU type: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import nfl_data_py as nfl\n",
        "from tabulate import tabulate\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import math\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "\n",
        "# Check GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU type: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = torch.nn.functional.mse_loss(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "def create_curriculum_batches(dataset, start_seq_len=50, end_seq_len=None, epochs_per_stage=5):\n",
        "    \"\"\"Creates curriculum learning stages\"\"\"\n",
        "    if end_seq_len is None:\n",
        "        end_seq_len = max(len(seq) for seq in dataset.qb_seqs)\n",
        "\n",
        "    num_stages = math.ceil((end_seq_len - start_seq_len) / 50)\n",
        "    stages = []\n",
        "\n",
        "    for i in range(num_stages):\n",
        "        curr_len = min(start_seq_len + i * 50, end_seq_len)\n",
        "        stages.extend([curr_len] * epochs_per_stage)\n",
        "\n",
        "    return stages\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0"
      ],
      "metadata": {
        "id": "oWMNpPR04OHf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "years = [2022, 2023, 2024]\n",
        "print(\"Loading play by play data...\")\n",
        "play_by_play = nfl.import_pbp_data(years, downcast=True)\n",
        "\n",
        "# Filter for passing plays\n",
        "pass_plays = play_by_play[play_by_play['pass_attempt'] == 1].copy()\n",
        "pass_plays = pass_plays.sort_values(['game_id', 'play_id'])\n",
        "\n",
        "# Fill missing values for new features\n",
        "numeric_columns = ['defenders_in_box', 'number_of_pass_rushers', 'temp',\n",
        "                  'wind', 'shotgun', 'no_huddle']\n",
        "pass_plays[numeric_columns] = pass_plays[numeric_columns].fillna(0)\n",
        "\n",
        "print(f\"Total plays: {len(pass_plays)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAp4zZTl4S97",
        "outputId": "d3d96cb1-b3ff-4780-d630-b5a6611b8408"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading play by play data...\n",
            "2022 done.\n",
            "2023 done.\n",
            "2024 done.\n",
            "Downcasting floats.\n",
            "Total plays: 54998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequence_features(play_by_play, qb_name, game_id):\n",
        "    \"\"\"Creates a sequence of play-by-play data with enhanced context\"\"\"\n",
        "    qb_plays = play_by_play[\n",
        "        (play_by_play['passer_player_name'] == qb_name) &\n",
        "        (play_by_play['pass_attempt'] == 1)\n",
        "    ]\n",
        "\n",
        "    if isinstance(game_id, float) and np.isinf(game_id):\n",
        "        previous_plays = qb_plays\n",
        "    else:\n",
        "        previous_plays = qb_plays[qb_plays['game_id'].astype(str) < str(game_id)]\n",
        "\n",
        "    sequence = []\n",
        "    for _, play in previous_plays.iterrows():\n",
        "        play_stats = [\n",
        "            # Core play stats\n",
        "            play['yards_gained'] if not np.isnan(play['yards_gained']) else 0,\n",
        "            play['pass_touchdown'] if not np.isnan(play['pass_touchdown']) else 0,\n",
        "            play['complete_pass'] if not np.isnan(play['complete_pass']) else 0,\n",
        "            play['air_yards'] if not np.isnan(play['air_yards']) else 0,\n",
        "            play['yards_after_catch'] if not np.isnan(play['yards_after_catch']) else 0,\n",
        "            play['qb_hit'] if not np.isnan(play['qb_hit']) else 0,\n",
        "            play['sack'] if not np.isnan(play['sack']) else 0,\n",
        "\n",
        "            # Game situation\n",
        "            play['score_differential'] if not np.isnan(play['score_differential']) else 0,\n",
        "            play['qtr'] if not np.isnan(play['qtr']) else 0,\n",
        "            play['down'] if not np.isnan(play['down']) else 0,\n",
        "            play['ydstogo'] if not np.isnan(play['ydstogo']) else 0,\n",
        "            play['yardline_100'] if not np.isnan(play['yardline_100']) else 0,\n",
        "\n",
        "            # Defensive pressure\n",
        "            play['defenders_in_box'] if not np.isnan(play['defenders_in_box']) else 0,\n",
        "            play['number_of_pass_rushers'] if not np.isnan(play['number_of_pass_rushers']) else 0,\n",
        "\n",
        "            # Weather conditions\n",
        "            play['temp'] if not np.isnan(play['temp']) else 70,\n",
        "            play['wind'] if not np.isnan(play['wind']) else 0,\n",
        "\n",
        "            # Binary indicators\n",
        "            play['shotgun'] if not np.isnan(play['shotgun']) else 0,\n",
        "            play['no_huddle'] if not np.isnan(play['no_huddle']) else 0,\n",
        "        ]\n",
        "        sequence.append(play_stats)\n",
        "\n",
        "    sequence = np.array(sequence)\n",
        "\n",
        "    # Apply linear weighting to emphasize recent plays\n",
        "    if len(sequence) > 0:\n",
        "        weights = np.linspace(1.0, 1.5, len(sequence))\n",
        "        sequence = sequence * weights[:, np.newaxis]\n",
        "\n",
        "    return sequence\n",
        "\n",
        "def create_defense_sequence(play_by_play, def_team, game_id):\n",
        "    \"\"\"Creates a sequence of play-by-play data for a defense with enhanced context\"\"\"\n",
        "    def_plays = play_by_play[\n",
        "        (play_by_play['defteam'] == def_team) &\n",
        "        (play_by_play['pass_attempt'] == 1)\n",
        "    ]\n",
        "\n",
        "    if isinstance(game_id, float) and np.isinf(game_id):\n",
        "        previous_plays = def_plays\n",
        "    else:\n",
        "        previous_plays = def_plays[def_plays['game_id'].astype(str) < str(game_id)]\n",
        "\n",
        "    sequence = []\n",
        "    for _, play in previous_plays.iterrows():\n",
        "        play_stats = [\n",
        "            # Same features as QB sequence\n",
        "            play['yards_gained'] if not np.isnan(play['yards_gained']) else 0,\n",
        "            play['pass_touchdown'] if not np.isnan(play['pass_touchdown']) else 0,\n",
        "            play['complete_pass'] if not np.isnan(play['complete_pass']) else 0,\n",
        "            play['air_yards'] if not np.isnan(play['air_yards']) else 0,\n",
        "            play['yards_after_catch'] if not np.isnan(play['yards_after_catch']) else 0,\n",
        "            play['qb_hit'] if not np.isnan(play['qb_hit']) else 0,\n",
        "            play['sack'] if not np.isnan(play['sack']) else 0,\n",
        "\n",
        "            play['score_differential'] if not np.isnan(play['score_differential']) else 0,\n",
        "            play['qtr'] if not np.isnan(play['qtr']) else 0,\n",
        "            play['down'] if not np.isnan(play['down']) else 0,\n",
        "            play['ydstogo'] if not np.isnan(play['ydstogo']) else 0,\n",
        "            play['yardline_100'] if not np.isnan(play['yardline_100']) else 0,\n",
        "\n",
        "            play['defenders_in_box'] if not np.isnan(play['defenders_in_box']) else 0,\n",
        "            play['number_of_pass_rushers'] if not np.isnan(play['number_of_pass_rushers']) else 0,\n",
        "\n",
        "            play['temp'] if not np.isnan(play['temp']) else 70,\n",
        "            play['wind'] if not np.isnan(play['wind']) else 0,\n",
        "\n",
        "            play['shotgun'] if not np.isnan(play['shotgun']) else 0,\n",
        "            play['no_huddle'] if not np.isnan(play['no_huddle']) else 0,\n",
        "        ]\n",
        "        sequence.append(play_stats)\n",
        "\n",
        "    sequence = np.array(sequence)\n",
        "\n",
        "    if len(sequence) > 0:\n",
        "        weights = np.linspace(1.0, 1.5, len(sequence))\n",
        "        sequence = sequence * weights[:, np.newaxis]\n",
        "\n",
        "    return sequence"
      ],
      "metadata": {
        "id": "34dPqUXJ4j4O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NFLDataset(Dataset):\n",
        "    def __init__(self, qb_sequences, def_sequences, y, qb_names, def_teams, indices, max_seq_len=2000):\n",
        "        self.qb_seqs = [torch.FloatTensor(qb_sequences[i]) for i in indices]\n",
        "        self.def_seqs = [torch.FloatTensor(def_sequences[i]) for i in indices]\n",
        "        self.y = torch.FloatTensor(y[indices])\n",
        "        self.qb_idx = torch.LongTensor([qb_to_idx[qb] for qb in qb_names[indices]])\n",
        "        self.team_idx = torch.LongTensor([team_to_idx[team] for team in def_teams[indices]])\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)  # Return the number of samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        qb_seq = self.qb_seqs[idx]\n",
        "        def_seq = self.def_seqs[idx]\n",
        "\n",
        "        # Truncate sequences if they're too long\n",
        "        if len(qb_seq) > self.max_seq_len:\n",
        "            qb_seq = qb_seq[-self.max_seq_len:]\n",
        "        if len(def_seq) > self.max_seq_len:\n",
        "            def_seq = def_seq[-self.max_seq_len:]\n",
        "\n",
        "        return (\n",
        "            qb_seq,\n",
        "            def_seq,\n",
        "            self.qb_idx[idx],\n",
        "            self.team_idx[idx],\n",
        "            self.y[idx]\n",
        "        )\n",
        "\n",
        "def pad_sequences(sequences, max_len=None):\n",
        "    \"\"\"Pad sequences to the same length\"\"\"\n",
        "    if max_len is None:\n",
        "        max_len = max(len(seq) for seq in sequences)\n",
        "\n",
        "    padded_seqs = []\n",
        "    for seq in sequences:\n",
        "        if len(seq) == 0:\n",
        "            padded_seq = np.zeros((max_len, seq.shape[1] if len(seq.shape) > 1 else 1))\n",
        "        else:\n",
        "            pad_length = max_len - len(seq)\n",
        "            if pad_length > 0:\n",
        "                padding = np.zeros((pad_length, seq.shape[1]))\n",
        "                padded_seq = np.vstack([seq, padding])\n",
        "            else:\n",
        "                padded_seq = seq[:max_len]\n",
        "        padded_seqs.append(padded_seq)\n",
        "\n",
        "    return np.array(padded_seqs)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"Custom collate function to handle variable-length sequences\"\"\"\n",
        "    qb_seqs, def_seqs, qb_idx, team_idx, y = zip(*batch)\n",
        "\n",
        "    # Pad sequences\n",
        "    qb_seqs_padded = pad_sequences([seq.numpy() for seq in qb_seqs])\n",
        "    def_seqs_padded = pad_sequences([seq.numpy() for seq in def_seqs])\n",
        "\n",
        "    return (\n",
        "        torch.FloatTensor(qb_seqs_padded),\n",
        "        torch.FloatTensor(def_seqs_padded),\n",
        "        torch.stack(qb_idx),\n",
        "        torch.stack(team_idx),\n",
        "        torch.stack(y)\n",
        "    )"
      ],
      "metadata": {
        "id": "ZdaKWuSS4m5a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QBPerformancePredictor(nn.Module):\n",
        "    def __init__(self, num_qbs, num_teams, max_seq_len=2000):  # Increased max sequence length\n",
        "        super().__init__()\n",
        "\n",
        "        self.qb_feature_dim = 18\n",
        "        self.def_feature_dim = 18\n",
        "        self.hidden_dim = 128\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # Feature embedding\n",
        "        self.feature_embedding = nn.Linear(self.qb_feature_dim, 64)\n",
        "\n",
        "        # Transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=64,\n",
        "            nhead=4,\n",
        "            dim_feedforward=256,\n",
        "            dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=3)\n",
        "\n",
        "        # Identity embeddings with positional encoding\n",
        "        self.qb_embedding = nn.Embedding(num_qbs, 32)\n",
        "        self.team_embedding = nn.Embedding(num_teams, 32)\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(1, max_seq_len, 64))\n",
        "\n",
        "        # Rest of the architecture remains the same...\n",
        "\n",
        "    def forward(self, qb_seq, def_seq, qb_idx, team_idx):\n",
        "        # Truncate sequences if they're too long\n",
        "        if qb_seq.size(1) > self.max_seq_len:\n",
        "            qb_seq = qb_seq[:, -self.max_seq_len:, :]\n",
        "        if def_seq.size(1) > self.max_seq_len:\n",
        "            def_seq = def_seq[:, -self.max_seq_len:, :]\n",
        "\n",
        "        # Project features\n",
        "        qb_embedded = self.feature_embedding(qb_seq)\n",
        "        def_embedded = self.feature_embedding(def_seq)\n",
        "\n",
        "        # Add positional encoding\n",
        "        seq_len = qb_embedded.size(1)\n",
        "        qb_embedded = qb_embedded + self.positional_encoding[:, :seq_len, :]\n",
        "        def_embedded = def_embedded + self.positional_encoding[:, :seq_len, :]\n",
        "\n",
        "        # Transform sequences\n",
        "        qb_encoded = self.transformer_encoder(qb_embedded)\n",
        "        def_encoded = self.transformer_encoder(def_embedded)\n",
        "\n",
        "        # Pool sequences with attention\n",
        "        qb_pooled = self.attention_pool(qb_encoded)\n",
        "        def_pooled = self.attention_pool(def_encoded)\n",
        "\n",
        "        # Get identity embeddings\n",
        "        qb_emb = self.qb_embedding(qb_idx)\n",
        "        team_emb = self.team_embedding(team_idx)\n",
        "\n",
        "        # Combine features\n",
        "        combined = torch.cat([qb_pooled, def_pooled, qb_emb, team_emb], dim=1)\n",
        "\n",
        "        # Main prediction path\n",
        "        x1 = self.fc1(combined)\n",
        "        x1 = self.layer_norm1(x1)\n",
        "        x1 = self.relu(x1)\n",
        "        x1 = self.dropout(x1)\n",
        "\n",
        "        x2 = self.fc2(x1)\n",
        "        x2 = self.layer_norm2(x2)\n",
        "        x2 = self.relu(x2)\n",
        "        x2 = self.dropout(x2)\n",
        "\n",
        "        main_out = self.fc3(x2)\n",
        "\n",
        "        # Auxiliary prediction path\n",
        "        aux_x = self.aux_fc1(combined)\n",
        "        aux_x = self.relu(aux_x)\n",
        "        aux_out = self.aux_fc2(aux_x)\n",
        "\n",
        "        return main_out, aux_out"
      ],
      "metadata": {
        "id": "Y0sV7w7L4z7Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, train_loader, optimizer, criterion, aux_criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_main_loss = 0\n",
        "    total_aux_loss = 0\n",
        "\n",
        "    with tqdm(train_loader, desc='Training') as pbar:\n",
        "        for batch in pbar:\n",
        "            qb_seq, def_seq, qb_idx, team_idx, y = [b.to(device) for b in batch]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Get main and auxiliary predictions\n",
        "            main_pred, aux_pred = model(qb_seq, def_seq, qb_idx, team_idx)\n",
        "\n",
        "            # Calculate losses\n",
        "            main_loss = criterion(main_pred, y)\n",
        "\n",
        "            # Create auxiliary targets (completion %, TD rate, INT rate)\n",
        "            aux_targets = torch.stack([\n",
        "                y[:, 3],  # completion percentage\n",
        "                y[:, 1] / torch.clamp(y[:, 0], min=1),  # TD rate\n",
        "                y[:, 2] / torch.clamp(y[:, 0], min=1)   # INT rate\n",
        "            ], dim=1).to(device)\n",
        "\n",
        "            aux_loss = aux_criterion(aux_pred, aux_targets)\n",
        "\n",
        "            # Combined loss\n",
        "            loss = main_loss + 0.3 * aux_loss\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_main_loss += main_loss.item()\n",
        "            total_aux_loss += aux_loss.item()\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'main_loss': f'{main_loss.item():.4f}',\n",
        "                'aux_loss': f'{aux_loss.item():.4f}'\n",
        "            })\n",
        "\n",
        "    return total_loss / len(train_loader), total_main_loss / len(train_loader), total_aux_loss / len(train_loader)\n",
        "\n",
        "def validate(model, val_loader, criterion, aux_criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_main_loss = 0\n",
        "    total_aux_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            qb_seq, def_seq, qb_idx, team_idx, y = [b.to(device) for b in batch]\n",
        "\n",
        "            main_pred, aux_pred = model(qb_seq, def_seq, qb_idx, team_idx)\n",
        "\n",
        "            main_loss = criterion(main_pred, y)\n",
        "\n",
        "            aux_targets = torch.stack([\n",
        "                y[:, 3],\n",
        "                y[:, 1] / torch.clamp(y[:, 0], min=1),\n",
        "                y[:, 2] / torch.clamp(y[:, 0], min=1)\n",
        "            ], dim=1).to(device)\n",
        "\n",
        "            aux_loss = aux_criterion(aux_pred, aux_targets)\n",
        "            loss = main_loss + 0.3 * aux_loss\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_main_loss += main_loss.item()\n",
        "            total_aux_loss += aux_loss.item()\n",
        "\n",
        "    return total_loss / len(val_loader), total_main_loss / len(val_loader), total_aux_loss / len(val_loader)"
      ],
      "metadata": {
        "id": "M1beU2Cu43_L"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sequences and prepare data\n",
        "print(\"\\nCreating sequences...\")\n",
        "qb_sequences = []\n",
        "def_sequences = []\n",
        "y_data = []\n",
        "\n",
        "# Group plays by game for target creation\n",
        "game_stats = pass_plays.groupby(['game_id', 'passer_player_name', 'defteam']).agg({\n",
        "    'yards_gained': 'sum',\n",
        "    'pass_touchdown': 'sum',\n",
        "    'interception': 'sum',\n",
        "    'complete_pass': 'sum',\n",
        "    'pass_attempt': 'sum',\n",
        "    'sack': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "game_stats['completion_percentage'] = (game_stats['complete_pass'] / game_stats['pass_attempt'] * 100).round(1)\n",
        "\n",
        "for _, game in game_stats.iterrows():\n",
        "    # Create sequences\n",
        "    qb_seq = create_sequence_features(pass_plays, game['passer_player_name'], game['game_id'])\n",
        "    def_seq = create_defense_sequence(pass_plays, game['defteam'], game['game_id'])\n",
        "\n",
        "    # Skip if no historical data\n",
        "    if len(qb_seq) == 0 or len(def_seq) == 0:\n",
        "        continue\n",
        "\n",
        "    # Create target variables\n",
        "    target = [\n",
        "        game['yards_gained'],\n",
        "        game['pass_touchdown'],\n",
        "        game['interception'],\n",
        "        game['completion_percentage'],\n",
        "        game['sack']\n",
        "    ]\n",
        "\n",
        "    qb_sequences.append(qb_seq)\n",
        "    def_sequences.append(def_seq)\n",
        "    y_data.append(target)\n",
        "\n",
        "# Create QB and team indices\n",
        "print(\"\\nCreating indices...\")\n",
        "qb_to_idx = {qb: idx for idx, qb in enumerate(game_stats['passer_player_name'].unique())}\n",
        "team_to_idx = {team: idx for idx, team in enumerate(game_stats['defteam'].unique())}\n",
        "\n",
        "# Scale target variables\n",
        "scaler = StandardScaler()\n",
        "y = np.array(y_data)\n",
        "y_scaled = scaler.fit_transform(y)\n",
        "\n",
        "# Split into train and test sets\n",
        "print(\"\\nSplitting data...\")\n",
        "train_size = int(0.8 * len(y_scaled))\n",
        "indices = np.arange(len(y_scaled))\n",
        "np.random.shuffle(indices)\n",
        "train_idx = indices[:train_size]\n",
        "test_idx = indices[train_size:]\n",
        "\n",
        "# Create data loaders\n",
        "# Define maximum sequence length\n",
        "max_seq_len = 2000  # Adjust this value as needed\n",
        "\n",
        "# Create data loaders with max_seq_len\n",
        "train_dataset = NFLDataset(\n",
        "    qb_sequences, def_sequences, y_scaled,\n",
        "    game_stats['passer_player_name'].values,\n",
        "    game_stats['defteam'].values, train_idx,\n",
        "    max_seq_len=max_seq_len  # Pass max_seq_len to the dataset\n",
        ")\n",
        "\n",
        "test_dataset = NFLDataset(\n",
        "    qb_sequences, def_sequences, y_scaled,\n",
        "    game_stats['passer_player_name'].values,\n",
        "    game_stats['defteam'].values, test_idx,\n",
        "    max_seq_len=max_seq_len  # Pass max_seq_len to the dataset\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collate_fn)\n",
        "\n",
        "# Initialize model with max_seq_len\n",
        "model = QBPerformancePredictor(\n",
        "    num_qbs=len(qb_to_idx),\n",
        "    num_teams=len(team_to_idx),\n",
        "    max_seq_len=max_seq_len  # Pass max_seq_len to the model\n",
        ").to(device)\n",
        "\n",
        "# Initialize training components\n",
        "criterion = FocalLoss()\n",
        "aux_criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "early_stopping = EarlyStopping(patience=10, min_delta=0.001)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    train_loss, train_main_loss, train_aux_loss = train_epoch(\n",
        "        model, train_loader, optimizer, criterion, aux_criterion, device\n",
        "    )\n",
        "\n",
        "    val_loss, val_main_loss, val_aux_loss = validate(\n",
        "        model, test_loader, criterion, aux_criterion, device\n",
        "    )\n",
        "\n",
        "    print(f\"Training Loss: {train_loss:.4f} (Main: {train_main_loss:.4f}, Aux: {train_aux_loss:.4f})\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f} (Main: {val_main_loss:.4f}, Aux: {val_aux_loss:.4f})\\n\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    early_stopping(val_loss)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered!\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510,
          "referenced_widgets": [
            "ffb1e91df2dc45de802e3670f1751232",
            "24f7c8e0517a4d27afe4cf2e57729d26",
            "f1645b16885a4ae586e1da6e1ba407a3",
            "32322996f2c74a16b74723e13df60cd6",
            "a2ff2f1582b24065bd0cbc23d434b564",
            "14f3b0e2e8a643d4a3c807744a2aaa92",
            "0f6c1b97c03640338ef3f19f994d81cf",
            "8b719521bee4458eae5b8c6f6c2ab59b",
            "e14251bca84340959b83a3e348e8acce",
            "228a2902f8864ff9b49e3e86f7b014bf",
            "38875a44e80246daa2e9b6bfada324f2"
          ]
        },
        "id": "vVKn9PPe5HPY",
        "outputId": "58a786a8-a2ad-41a5-cdc0-912298d8ecd2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating sequences...\n",
            "\n",
            "Creating indices...\n",
            "\n",
            "Splitting data...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/86 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffb1e91df2dc45de802e3670f1751232"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (1657) must match the size of tensor b (1406) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c8df38c70d68>\u001b[0m in \u001b[0;36m<cell line: 98>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     train_loss, train_main_loss, train_aux_loss = train_epoch(\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     )\n",
            "\u001b[0;32m<ipython-input-8-dc73263ec115>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, optimizer, criterion, aux_criterion, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# Get main and auxiliary predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mmain_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqb_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdef_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqb_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteam_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# Calculate losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-c2050731a5d6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, qb_seq, def_seq, qb_idx, team_idx)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqb_embedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mqb_embedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqb_embedded\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_encoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mdef_embedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdef_embedded\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_encoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Transform sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1657) must match the size of tensor b (1406) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_qb_performance(qb_name, def_team):\n",
        "    \"\"\"Make predictions for a QB against a specific defense\"\"\"\n",
        "    if qb_name not in qb_to_idx:\n",
        "        raise ValueError(f\"Quarterback {qb_name} not found in data.\")\n",
        "    if def_team not in team_to_idx:\n",
        "        raise ValueError(f\"Defense team {def_team} not found in data.\")\n",
        "\n",
        "    qb_seq = create_sequence_features(pass_plays, qb_name, float('inf'))\n",
        "    def_seq = create_defense_sequence(pass_plays, def_team, float('inf'))\n",
        "\n",
        "    if len(qb_seq) == 0:\n",
        "        raise ValueError(f\"No historical data found for QB: {qb_name}\")\n",
        "    if len(def_seq) == 0:\n",
        "        raise ValueError(f\"No historical data found for defense: {def_team}\")\n",
        "\n",
        "    qb_seq_tensor = torch.FloatTensor(qb_seq).unsqueeze(0).to(device)\n",
        "    def_seq_tensor = torch.FloatTensor(def_seq).unsqueeze(0).to(device)\n",
        "    qb_idx = torch.LongTensor([qb_to_idx[qb_name]]).to(device)\n",
        "    team_idx = torch.LongTensor([team_to_idx[def_team]]).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        main_pred, _ = model(qb_seq_tensor, def_seq_tensor, qb_idx, team_idx)\n",
        "\n",
        "    prediction = scaler.inverse_transform(main_pred.cpu().numpy())\n",
        "\n",
        "    return {\n",
        "        'yards_gained': round(float(prediction[0, 0]), 1),\n",
        "        'pass_touchdown': round(float(prediction[0, 1]), 1),\n",
        "        'interception': round(float(prediction[0, 2]), 1),\n",
        "        'completion_percentage': round(float(prediction[0, 3]), 1),\n",
        "        'sack': round(float(prediction[0, 4]), 1)\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "try:\n",
        "    prediction = predict_qb_performance(\"P.Mahomes\", \"BUF\")\n",
        "    print(\"\\nPredicted QB Performance:\")\n",
        "    for stat, value in prediction.items():\n",
        "        print(f\"{stat}: {value}\")\n",
        "except ValueError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "5zBn6Y9Z5Khi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}